Speech Analysis

After fetching the complete speeches of user's choice from our database, we want to perform some basic analysis on both speeches and return the output. We have chosen the python library "textblob" for text processing which is built on powerful processing tools in "NLTK" and "pattern". 

For each speech, we parse it and return the word counts. We also display the keywords of the speech by extracting all noun phrases and returning the top 3 noun phrases after removing the stopwords. We can also display those keywords in context by returning the word and the three words either side using KWIC method. 

Another important analysis we want to include is sentiment analysis. "textblob" has built-in function that allows us to perform sentiment analysis directly. We can specify either PatternAnalyzer (based on the pattern library) or NaiveBayesAnalyzer (an NLTK classifier). In addition, Thomas et al (2006) suggests an alternative way to evaluate formal Congressional speeches using Support Vector Machines(SVM). We could potentially implement their method if time permits. 

Last but not least, we want to output a "proximity score" that shows the proximity of two speeches. There are multiple distance metrics available in NLTK package including edit distance, jaccard distance and masi distance. As metrics, they must satisfy the following three requirements:

1. d(a, a) = 0
2. d(a, b) >= 0
3. d(a, c) <= d(a, b) + d(b, c)


We decided to go with jaccard distance in represent the "similarity score". Jaccard similarity coefficient measures the similarity and diversity of sample sets after stopword removal. The "proximity score" ranges from 0 to 1, with 0 being identical and 1 being irrelavant. 

References:
https://textblob.readthedocs.io/en/dev/
http://www.cs.cornell.edu/home/llee/papers/tpl-convote.dec06.pdf
http://bommaritollc.com/2014/06/12/fuzzy-match-sentences-python/
